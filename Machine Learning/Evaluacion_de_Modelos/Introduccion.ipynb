{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpAqTNvXKaVGdmaxsQGpO+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brandon-Bernal-Alarcon/Notas/blob/main/Machine%20Learning/Evaluacion_de_Modelos/Introduccion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluación y selección de modelos**"
      ],
      "metadata": {
        "id": "YTwgj5nSFOQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el aprendizaje automático supervisado, la **evaluación del modelo** constituye una etapa central dentro del flujo de trabajo, una vez entrenado un modelo, es indispensable medir su desempeño para determinar si satisface los objetivos reales de la aplicación, esta evaluación no solo permite comparar distintos modelos entrenados, sino también seleccionar configuraciones de hiperparámetros y orientar mejoras posteriores en la fase de refinamiento del modelo.\n",
        "\n",
        "Aunque métricas simples como la precisión (accuracy) en clasificación o el coeficiente de determinación $R^2$ en regresión son comúnmente utilizadas, estas medidas pueden ser insuficientes para describir adecuadamente el comportamiento de un modelo en escenarios reales."
      ],
      "metadata": {
        "id": "X91QlYokFTG6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Limitaciones de las métricas simples**\n",
        "\n",
        "La precisión se define como la fracción de instancias correctamente clasificadas sobre el total de observaciones N.\n",
        "\n",
        "$$Acurrancy = \\frac{\\text{Predicciones correctas}}{\\text{Total de Predicciones}}$$\n",
        "\n",
        "Si bien es fácil de interpretar, esta métrica presenta limitaciones importantes:\n",
        "\n",
        "- No distingue entre distintos tipos de errores.\n",
        "\n",
        "- Asume implícitamente que todos los errores tienen el mismo costo.\n",
        "\n",
        "- Puede ser altamente engañosa en conjuntos de datos con clases desbalanceadas.\n",
        "\n",
        "En aplicaciones reales, como sistemas de búsqueda, recomendación, detección de fraude o diagnóstico médico, los costos asociados a errores de distinta naturaleza suelen ser muy diferentes, por tanto, una métrica única como la precisión no siempre refleja el verdadero desempeño del modelo."
      ],
      "metadata": {
        "id": "hg_Iy0iPFnIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejemplo práctico: conjunto de datos de dígitos**\n",
        "\n",
        "Se utilizará el conjunto de datos de dígitos de sklearn, originalmente, este conjunto tiene diez clases balanceadas (dígitos del 0 al 9), sin embargo, para ilustrar el problema del desbalance, se transforma en un problema binario:\n",
        "\n",
        "Clase positiva: dígito 1\n",
        "\n",
        "Clase negativa: todos los demás dígitos"
      ],
      "metadata": {
        "id": "1WN9RS3sK74J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib notebook\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "dataset = load_digits()\n",
        "X, y = dataset.data, dataset.target\n",
        "\n",
        "for class_name, class_count in zip(dataset.target_names, np.bincount(dataset.target)):\n",
        "    print(class_name,class_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aXlRNA7KkLM",
        "outputId": "4d461778-5c57-4af1-b28b-4ff813bfdbfe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 178\n",
            "1 182\n",
            "2 177\n",
            "3 183\n",
            "4 181\n",
            "5 182\n",
            "6 181\n",
            "7 179\n",
            "8 174\n",
            "9 180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_binary_imbalanced = y.copy()\n",
        "y_binary_imbalanced[y_binary_imbalanced != 1] = 0\n",
        "\n",
        "print('Original labels:\\t', y[1:30])\n",
        "print('New binary labels:\\t', y_binary_imbalanced[1:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzexUR0pLSvQ",
        "outputId": "ab49388c-4647-43fc-9783-310e5de7e9b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original labels:\t [1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9]\n",
            "New binary labels:\t [1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.bincount(y_binary_imbalanced)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7SxC9qVLfIl",
        "outputId": "001b7476-939e-4b6d-8369-31d8f262157a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1615,  182])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este conteo muestra un fuerte desbalance: muchas instancias negativas y relativamente pocas positivas."
      ],
      "metadata": {
        "id": "KC4gRalvLPX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Entrenamiento de un clasificador real**\n",
        "\n",
        "Se entrena un clasificador SVM con kernel RBF sobre este conjunto binario desbalanceado y se evalúa su precisión:"
      ],
      "metadata": {
        "id": "018EzvVHOdOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary_imbalanced, random_state=0)\n",
        "\n",
        "# Accuracy of Support Vector Machine classifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
        "svm.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PpbxfRUOfUc",
        "outputId": "5f1787b6-ff5d-4e4c-91db-7c382205b5d1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9955555555555555"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El valor obtenido es cercano al 99%, lo cual podría parecer un buen desempeño a primera vista."
      ],
      "metadata": {
        "id": "uG4a4vTnOzom"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clasificador ficticio como línea base (DummyClassifier)**\n",
        "\n",
        "Para evaluar si este resultado es realmente significativo, se introduce el uso de DummyClassifier, que proporciona una línea base de desempeño nulo."
      ],
      "metadata": {
        "id": "Y9GzflAwO3w_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DummyClassifier es un clasificador que realiza predicciones utilizando reglas simples, que pueden ser útiles como base para la comparación con clasificadores reales, especialmente con clases desequilibradas."
      ],
      "metadata": {
        "id": "daqWQczLPFEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "# Negative class (0) is most frequent\n",
        "dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
        "# Therefore the dummy 'most_frequent' classifier always predicts class 0\n",
        "y_dummy_predictions = dummy_majority.predict(X_test)\n",
        "\n",
        "y_dummy_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb1bk3chO54-",
        "outputId": "ada162c5-37c1-4e68-97ef-9c2cf7e8a1ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_majority.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9xgr2JlPNit",
        "outputId": "085ac6d9-c59d-4089-e32a-0b6ae3854679"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9044444444444445"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este clasificador siempre predice la clase mayoritaria (clase negativa). Sorprendentemente, su precisión también es cercana al 90%, lo que demuestra que la precisión del SVM no es particularmente impresionante en este contexto."
      ],
      "metadata": {
        "id": "1k3i6HGZPI0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Otras estrategias de DummyClassifier**\n",
        "\n",
        "Otras estrategias útiles para análisis comparativo:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "DummyClassifier(strategy='stratified')\n",
        "DummyClassifier(strategy='uniform')\n",
        "DummyClassifier(strategy='constant', constant=1)\n",
        "```\n",
        "\n",
        "Estas estrategias permiten:\n",
        "\n",
        "- Simular predicciones aleatorias según la distribución de clases.\n",
        "\n",
        "- Forzar predicciones positivas para poder calcular métricas como F-score.\n",
        "\n",
        "- Obtener referencias útiles para entender los tipos de errores esperados."
      ],
      "metadata": {
        "id": "8w-9513-PaDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparación con un modelo mejor ajustado**\n",
        "\n",
        "Al modificar el kernel del SVM a uno lineal, el desempeño mejora significativamente:"
      ],
      "metadata": {
        "id": "JkW07-BRPolS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
        "svm.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-zoxQg6PRXV",
        "outputId": "979d283c-e788-4208-d7a8-40e35086c429"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso, la precisión se eleva hasta aproximadamente 98%, superando claramente la línea base del DummyClassifier, lo que indica que el modelo sí está capturando patrones relevantes."
      ],
      "metadata": {
        "id": "Lp7hWiFHPyxp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este análisis muestra que:\n",
        "\n",
        "- Una precisión alta no garantiza un buen modelo.\n",
        "\n",
        "- Siempre debe compararse el desempeño contra una línea base trivial.\n",
        "\n",
        "- Un modelo cercano al rendimiento de un DummyClassifier suele indicar:<br>\n",
        "       - características poco informativas,<br>\n",
        "       - mala elección de kernel,<br>\n",
        "       - hiperparámetros inadecuados, <br>\n",
        "       - o fuerte desbalance de clases.\n",
        "\n",
        "Por ello, en problemas desbalanceados es fundamental utilizar métricas adicionales más allá de la precisión.\n",
        "\n",
        "## **Resultados clave**\n",
        "\n",
        "La evaluación es una etapa crítica del flujo de trabajo.\n",
        "\n",
        "Métricas simples pueden ser insuficientes o engañosas.\n",
        "\n",
        "El contexto de la aplicación determina qué métricas son relevantes.\n",
        "\n",
        "Los clasificadores ficticios proporcionan una referencia esencial.\n",
        "\n",
        "Es necesario un análisis más detallado de los errores del modelo."
      ],
      "metadata": {
        "id": "OtYDlR53P2jG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Métricas de evaluación vs funciones objetivo**\n",
        "\n",
        "Un aspecto clave es la diferencia entre **Función objetivo de entrenamiento** que es aquella que el algoritmo optimiza directamente durante el ajuste del modelo (por ejemplo, una función de pérdida convexa) y **Métrica de evaluación** que es aquella que se utiliza para juzgar el éxito del modelo en función de los objetivos de la aplicación.\n",
        "\n",
        "En muchos casos, **la función objetivo** se elige por razones computacionales o de optimización, mientras que la **métrica de evaluación** está alineada con criterios de negocio, impacto clínico o experiencia del usuario, por ello, ambas no necesariamente coinciden.\n",
        "\n",
        "Un ejemplo claro es el de los motores de búsqueda comerciales, el modelo puede entrenarse para predecir relevancia de documentos, pero su evaluación final puede involucrar métricas indirectas como duración de sesiones, tasas de clics o satisfacción del usuario."
      ],
      "metadata": {
        "id": "coCIt3HoF2Sb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importancia del contexto de la aplicación**\n",
        "\n",
        "La elección de métricas de evaluación debe estar guiada por los objetivos específicos del problema:\n",
        "\n",
        "En tareas donde todas las clases son igualmente importantes y balanceadas (por ejemplo, reconocimiento de dígitos manuscritos), la precisión puede ser suficiente.\n",
        "\n",
        "En aplicaciones médicas, puede ser prioritario minimizar falsos negativos, incluso a costa de aumentar falsos positivos.\n",
        "\n",
        "En aplicaciones orientadas al usuario (recomendaciones, publicidad, búsqueda), los falsos positivos pueden ser especialmente perjudiciales para la experiencia del usuario.\n",
        "\n",
        "Por esta razón, en la práctica se suelen utilizar paneles de métricas múltiples en lugar de una sola medida de desempeño."
      ],
      "metadata": {
        "id": "-NGOp9JwGejZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Problemas con clases desbalanceadas**\n",
        "\n",
        "El concepto de clases desbalanceadas es muy común en problemas reales de Machine Learning. En estos escenarios, la clase negativa suele ser ampliamente mayoritaria, mientras que la clase positiva es rara.\n",
        "\n",
        "Ejemplos típicos incluyen:\n",
        "\n",
        "- Detección de fraude con tarjetas de crédito.\n",
        "\n",
        "- Recomendaciones de productos relevantes.\n",
        "\n",
        "- Identificación de eventos poco frecuentes.\n",
        "\n",
        "En estos casos, un clasificador que siempre predice la clase mayoritaria puede alcanzar una precisión muy alta sin aportar ningún valor predictivo real."
      ],
      "metadata": {
        "id": "n82bdtoDGqIq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Clasificadores ficticios como línea base**\n",
        "\n",
        "Para evidenciar este problema, se introduce el uso de **DummyClassifier** en scikit-learn, estos clasificadores no aprenden patrones a partir de los datos, sino que siguen reglas simples como:\n",
        "\n",
        "- Predecir siempre la clase más frecuente.\n",
        "\n",
        "- Predecir clases de manera aleatoria según su distribución.\n",
        "\n",
        "- Predecir clases de forma uniforme.\n",
        "\n",
        "El desempeño de un DummyClassifier define una línea base de precisión nula, que sirve como comprobación de cordura, si un modelo entrenado obtiene un rendimiento cercano al de un clasificador ficticio, esto indica que el modelo no está aprendiendo información relevante o que existen problemas con las características, el kernel o los hiperparámetros."
      ],
      "metadata": {
        "id": "c6c9VKTdG5BE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implicaciones para la selección de modelos**\n",
        "\n",
        "El análisis presentado conduce a que la selección de modelos no debe basarse únicamente en la precisión, especialmente en problemas desbalanceados, es necesario utilizar métricas adicionales que permitan entender los tipos de errores que comete el modelo, comparar modelos en función de los costos reales de esos errores, elegir configuraciones que optimicen el desempeño relevante para la aplicación.\n",
        "\n",
        "Este razonamiento motiva el estudio detallado de la matriz de confusión y de métricas como precisión, recall y F-score, que se desarrollan en el siguiente video."
      ],
      "metadata": {
        "id": "C9LIJ9iHHN4_"
      }
    }
  ]
}