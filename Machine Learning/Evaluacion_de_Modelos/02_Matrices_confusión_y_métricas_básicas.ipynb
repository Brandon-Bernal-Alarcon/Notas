{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwwckcHmtIh8VPA7YQ8Esb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Brandon-Bernal-Alarcon/Notas/blob/main/Machine%20Learning/Evaluacion_de_Modelos/02_Matrices_confusi%C3%B3n_y_m%C3%A9tricas_b%C3%A1sicas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Matrices de confusi贸n y m茅tricas b谩sicas de evaluaci贸n**"
      ],
      "metadata": {
        "id": "3VK0FgfwR6cm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el notebook anterior se mostr贸 que la precisi贸n (accuracy), aunque ampliamente utilizada, puede ser insuficiente para evaluar el desempe帽o real de un clasificador, especialmente en problemas con clases desbalanceadas, en este notebook se profundiza en el an谩lisis del rendimiento de modelos de clasificaci贸n binaria introduciendo la matriz de confusi贸n y un conjunto de m茅tricas derivadas que permiten distinguir entre distintos tipos de errores.\n",
        "\n",
        "El objetivo central es comprender c贸mo y por qu茅 un clasificador se equivoca, y c贸mo esa informaci贸n puede utilizarse para seleccionar modelos acordes a los objetivos espec铆ficos de una aplicaci贸n real."
      ],
      "metadata": {
        "id": "E5xBQF4nSNYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Matriz de confusi贸n**"
      ],
      "metadata": {
        "id": "WRMQzr8rSZqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En un problema de clasificaci贸n binaria, cada predicci贸n del modelo cae en una de cuatro categor铆as posibles:\n",
        "\n",
        "- Verdadero Negativo (TN): la instancia pertenece a la clase negativa y el clasificador predice negativo.\n",
        "\n",
        "- Falso Positivo (FP): la instancia pertenece a la clase negativa pero el clasificador predice positivo (error tipo I).\n",
        "\n",
        "- Falso Negativo (FN): la instancia pertenece a la clase positiva pero el clasificador predice negativo (error tipo II).\n",
        "\n",
        "- Verdadero Positivo (TP): la instancia pertenece a la clase positiva y el clasificador predice positivo.\n",
        "\n",
        "\n",
        "Estas cantidades se organizan en la matriz de confusi贸n:\n",
        "\n",
        "|                     | Pred. Negativa | Pred. Positiva |\n",
        "|---------------------|---------------:|---------------:|\n",
        "| **Real Negativa**   | TN             | FP             |\n",
        "| **Real Positiva**   | FN             | TP             |\n",
        "\n",
        "\n",
        "La matriz de confusi贸n proporciona una descripci贸n completa del comportamiento del clasificador y constituye la base para la definici贸n de m茅tricas de evaluaci贸n m谩s informativas que la precisi贸n\n",
        "\n"
      ],
      "metadata": {
        "id": "exDcaSd2SctK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **M茅tricas derivadas de la matriz de confusi贸n**\n",
        "\n",
        "**Precisi贸n (Accuracy)**\n",
        "\n",
        "$$Acurracy = \\frac{TP+TN}{N}$$\n",
        "\n",
        "Corresponde a la fracci贸n de predicciones correctas y equivale a la suma de la diagonal principal de la matriz de confusi贸n dividida entre el n煤mero total de instancias.\n",
        "\n",
        "**Error de clasificaci贸n**\n",
        "\n",
        "$$Error = \\frac{FP + FN}{N} = 1 - Acurracy $$\n",
        "\n",
        "Mide la fracci贸n total de errores cometidos por el clasificador\n",
        "\n",
        "**Recall (sensibilidad, tasa de verdaderos positivos)**\n",
        "\n",
        "$$ Recall = \\frac{TP}{TP+TN}$$\n",
        "\n",
        "Eval煤a la capacidad del clasificador para detectar correctamente los casos positivos, es una m茅trica clave cuando los falsos negativos son especialmente costosos, como en aplicaciones m茅dicas o legales.\n",
        "\n",
        "**Precisi贸n (Precision)**\n",
        "\n",
        "$$Precisi贸n = \\frac{TP}{TP+FP} $$\n",
        "\n",
        "Mide qu茅 proporci贸n de las predicciones positivas realizadas por el modelo son correctas. Es fundamental cuando los falsos positivos tienen consecuencias negativas importantes, como en sistemas de recomendaci贸n o motores de b煤squeda.\n",
        "\n",
        "**Tasa de falsos positivos y especificidad**\n",
        "\n",
        "\n",
        "$$ FPR = \\frac{FP}{FP + TP} $$\n",
        "\n",
        "La especificidad se define como:\n",
        "\n",
        "$$ specificity = 1 - FPR $$\n",
        "\n",
        "Estas m茅tricas cuantifican el comportamiento del clasificador sobre la clase negativa."
      ],
      "metadata": {
        "id": "XuLrAfzayhNP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Compromiso entre precisi贸n y recall**\n",
        "\n",
        "una disyuntiva fundamental en Machine LearninG es:\n",
        "\n",
        "Incrementar la precisi贸n suele reducir el recall.\n",
        "\n",
        "Incrementar el recall suele reducir la precisi贸n.\n",
        "\n",
        "La elecci贸n del umbral de decisi贸n determina este equilibrio y debe alinearse con el objetivo de la aplicaci贸n. No existe un clasificador universalmente 贸ptimo, la m茅trica adecuada depende del contexto."
      ],
      "metadata": {
        "id": "7KMJyrB6z5La"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Puntuaci贸n F y F1-score**\n",
        "\n",
        "Para combinar precisi贸n y recall en una sola m茅trica se utiliza la puntuaci贸n F:\n",
        "\n",
        "$$F_尾 = (1+ 尾^2)*\\frac{Precisi贸n*Recall}{(尾^2*Presici贸n)+Recall} $$\n",
        "\n",
        "El caso $=1$ corresponde a la puntuaci贸n F1, que pondera ambas m茅tricas de manera equitativa:\n",
        "\n",
        "$$F_1 = (2)*\\frac{Precisi贸n*Recall}{(Presici贸n)+Recall} $$\n",
        "\n",
        "Valores de $尾<1$ enfatizan la precisi贸n, mientras que valores de $尾>1$ enfatizan el recall."
      ],
      "metadata": {
        "id": "8pSUdq-t0DVr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implementaci贸n en Python con scikit-learn**\n",
        "\n",
        "A partir de un clasificador entrenado (por ejemplo, un 谩rbol de decisi贸n), se calculan las m茅tricas de evaluaci贸n utilizando sklearn.metrics:"
      ],
      "metadata": {
        "id": "yE_EZ-eN022E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib notebook\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "dataset = load_digits()\n",
        "X, y = dataset.data, dataset.target\n",
        "\n",
        "for class_name, class_count in zip(dataset.target_names, np.bincount(dataset.target)):\n",
        "    print(class_name,class_count)\n",
        "\n",
        "\n",
        "y_binary_imbalanced = y.copy()\n",
        "y_binary_imbalanced[y_binary_imbalanced != 1] = 0\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary_imbalanced, random_state=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nQSEI0j1XPf",
        "outputId": "567f55d9-1f42-4ef4-dbb1-a6651a7a8eb5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 178\n",
            "1 182\n",
            "2 177\n",
            "3 183\n",
            "4 181\n",
            "5 182\n",
            "6 181\n",
            "7 179\n",
            "8 174\n",
            "9 180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier(max_depth=2).fit(X_train, y_train)\n",
        "tree_predicted = dt.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, tree_predicted)\n",
        "\n",
        "print('Decision tree classifier (max_depth = 2)\\n', confusion)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "confusion_matrix(y_test, tree_predicted)\n",
        "precision_score(y_test, tree_predicted)\n",
        "recall_score(y_test, tree_predicted)\n",
        "f1_score(y_test, tree_predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReK12luY070A",
        "outputId": "02772614-e881-4968-ddd5-023c55faad8a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision tree classifier (max_depth = 2)\n",
            " [[400   7]\n",
            " [ 17  26]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6842105263157895"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "print('Accuracy: {:.2f}'.format(accuracy_score(y_test, tree_predicted)))\n",
        "print('Precision: {:.2f}'.format(precision_score(y_test, tree_predicted)))\n",
        "print('Recall: {:.2f}'.format(recall_score(y_test, tree_predicted)))\n",
        "print('F1: {:.2f}'.format(f1_score(y_test, tree_predicted)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj-JPBkx08tD",
        "outputId": "1535e7ea-ac8f-454e-bd17-96adb68a73c9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.95\n",
            "Precision: 0.79\n",
            "Recall: 0.60\n",
            "F1: 0.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Comparaci贸n de modelos mediante matrices de confusi贸n**\n",
        "\n",
        "En este video se comparan expl铆citamente distintos clasificadores utilizando matrices de confusi贸n, lo que permite analizar no solo cu谩ntos errores comete cada modelo, sino qu茅 tipo de errores."
      ],
      "metadata": {
        "id": "XLgU5GOa2idr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clasificadores ficticios (DummyClassifier)**\n",
        "Clasificador de la clase mayoritaria\n",
        "\n",
        "Este clasificador siempre predice la clase m谩s frecuente (clase negativa, 0):"
      ],
      "metadata": {
        "id": "2EIywQoB2mAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "\n",
        "# Negative class (0) is most frequent\n",
        "dummy_majority = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
        "y_majority_predicted = dummy_majority.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, y_majority_predicted)\n",
        "\n",
        "\n",
        "print('Most frequent class (dummy classifier)\\n',\n",
        "      confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4mAFwrU2vE1",
        "outputId": "4107558f-076c-4fbd-f5c2-053d3e567896"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most frequent class (dummy classifier)\n",
            " [[407   0]\n",
            " [ 43   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretaci贸n:\n",
        "\n",
        "El clasificador nunca predice la clase positiva.\n",
        "\n",
        "Obtiene una accuracy aparentemente alta debido al desbalance.\n",
        "\n",
        "Recall para la clase positiva es 0."
      ],
      "metadata": {
        "id": "wVJqCGtW29CU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clasificador aleatorio proporcional**\n",
        "\n",
        "Este clasificador predice clases aleatoriamente respetando la proporci贸n de clases del conjunto de entrenamiento:"
      ],
      "metadata": {
        "id": "l_GzL1Sd2_lB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# produces random predictions w/ same class proportion as training set\n",
        "dummy_classprop = DummyClassifier(strategy='stratified').fit(X_train, y_train)\n",
        "y_classprop_predicted = dummy_classprop.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, y_classprop_predicted)\n",
        "\n",
        "\n",
        "print('Random class-proportional prediction (dummy classifier)\\n', confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnxH3pSE3DTS",
        "outputId": "d7b2651d-5689-4131-f66d-4a08674d2918"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random class-proportional prediction (dummy classifier)\n",
            " [[375  32]\n",
            " [ 39   4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretaci贸n:\n",
        "\n",
        "El modelo detecta algunos positivos, pero con muchos falsos positivos y falsos negativos.\n",
        "\n",
        "Sirve como l铆nea base m铆nima para evaluar modelos reales."
      ],
      "metadata": {
        "id": "np6Imb2d3Hx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Machine (kernel lineal)**"
      ],
      "metadata": {
        "id": "sg0lq8L23Khp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "svm = SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
        "svm_predicted = svm.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, svm_predicted)\n",
        "\n",
        "\n",
        "print('Support vector machine classifier (linear kernel, C=1)\\n', confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZJd20NK3Lwg",
        "outputId": "aa09fa4b-e565-4efb-af9a-c99333ff1794"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Support vector machine classifier (linear kernel, C=1)\n",
            " [[402   5]\n",
            " [  5  38]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretaci贸n:\n",
        "\n",
        "Excelente balance entre falsos positivos y falsos negativos.\n",
        "\n",
        "Alta precision y recall para la clase positiva.\n",
        "\n",
        "Representa una mejora sustancial frente a los clasificadores ficticios."
      ],
      "metadata": {
        "id": "0PF2v2tX3S2b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regresi贸n log铆stica**"
      ],
      "metadata": {
        "id": "HLPrjyv53XNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression().fit(X_train, y_train)\n",
        "lr_predicted = lr.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, lr_predicted)\n",
        "\n",
        "print('Logistic regression classifier (default settings)\\n', confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mhbr8WdR3VsM",
        "outputId": "73fdfad5-2098-43e0-a2a3-aa30570575cd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic regression classifier (default settings)\n",
            " [[401   6]\n",
            " [  8  35]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretaci贸n:\n",
        "\n",
        "Rendimiento comparable al SVM.\n",
        "\n",
        "Ligero aumento en falsos negativos.\n",
        "\n",
        "Advertencia de convergencia indica posible necesidad de escalar datos o aumentar max_iter."
      ],
      "metadata": {
        "id": "vX1HRW9L3esh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**rbol de decisi贸n**"
      ],
      "metadata": {
        "id": "IDSY5KJw3grm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "dt = DecisionTreeClassifier(max_depth=2).fit(X_train, y_train)\n",
        "tree_predicted = dt.predict(X_test)\n",
        "confusion = confusion_matrix(y_test, tree_predicted)\n",
        "\n",
        "\n",
        "print('Decision tree classifier (max_depth = 2)\\n', confusion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4k_9xPUA3jJd",
        "outputId": "ccf3e086-0b07-4edf-85c3-7ab85e418869"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision tree classifier (max_depth = 2)\n",
            " [[400   7]\n",
            " [ 17  26]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretaci贸n:\n",
        "\n",
        "Mayor n煤mero de falsos negativos.\n",
        "\n",
        "Menor recall para la clase positiva.\n",
        "\n",
        "rbol poco profundo prioriza simplicidad a costa de desempe帽o."
      ],
      "metadata": {
        "id": "X4xZN8JN3nX9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reporte de clasificaci贸n**\n",
        "\n",
        "Para obtener un resumen completo del desempe帽o del modelo, se utiliza:"
      ],
      "metadata": {
        "id": "XtQ7yXtM2IVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combined report with all above metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, tree_predicted, target_names=['not 1', '1']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLadfPoP2YVG",
        "outputId": "4ebe3386-6d33-460d-ab0f-2e43151d39a4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       not 1       0.96      0.98      0.97       407\n",
            "           1       0.79      0.60      0.68        43\n",
            "\n",
            "    accuracy                           0.95       450\n",
            "   macro avg       0.87      0.79      0.83       450\n",
            "weighted avg       0.94      0.95      0.94       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Random class-proportional (dummy)\\n',\n",
        "      classification_report(y_test, y_classprop_predicted, target_names=['not 1', '1']))\n",
        "print('SVM\\n',\n",
        "      classification_report(y_test, svm_predicted, target_names = ['not 1', '1']))\n",
        "print('Logistic regression\\n',\n",
        "      classification_report(y_test, lr_predicted, target_names = ['not 1', '1']))\n",
        "print('Decision tree\\n',\n",
        "      classification_report(y_test, tree_predicted, target_names = ['not 1', '1']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nenZFDAd2aYB",
        "outputId": "9331cee5-cbc0-4641-b95b-d227b68ddb0c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random class-proportional (dummy)\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       not 1       0.91      0.92      0.91       407\n",
            "           1       0.11      0.09      0.10        43\n",
            "\n",
            "    accuracy                           0.84       450\n",
            "   macro avg       0.51      0.51      0.51       450\n",
            "weighted avg       0.83      0.84      0.84       450\n",
            "\n",
            "SVM\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       not 1       0.99      0.99      0.99       407\n",
            "           1       0.88      0.88      0.88        43\n",
            "\n",
            "    accuracy                           0.98       450\n",
            "   macro avg       0.94      0.94      0.94       450\n",
            "weighted avg       0.98      0.98      0.98       450\n",
            "\n",
            "Logistic regression\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       not 1       0.98      0.99      0.98       407\n",
            "           1       0.85      0.81      0.83        43\n",
            "\n",
            "    accuracy                           0.97       450\n",
            "   macro avg       0.92      0.90      0.91       450\n",
            "weighted avg       0.97      0.97      0.97       450\n",
            "\n",
            "Decision tree\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       not 1       0.96      0.98      0.97       407\n",
            "           1       0.79      0.60      0.68        43\n",
            "\n",
            "    accuracy                           0.95       450\n",
            "   macro avg       0.87      0.79      0.83       450\n",
            "weighted avg       0.94      0.95      0.94       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El classification report incluye:\n",
        "\n",
        "- Precision\n",
        "\n",
        "- Recall\n",
        "\n",
        "- F1-score\n",
        "\n",
        "- Soporte (n煤mero de instancias por clase)\n",
        "\n",
        "Este reporte facilita la comparaci贸n entre distintos modelos entrenados sobre el mismo conjunto de datos."
      ],
      "metadata": {
        "id": "jljmPVLn3xmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusiones**\n",
        "\n",
        "La matriz de confusi贸n es una herramienta esencial para comprender el comportamiento de un clasificador.\n",
        "\n",
        "M茅tricas como precision, recall y F1-score proporcionan perspectivas complementarias del desempe帽o del modelo.\n",
        "\n",
        "No existe una m茅trica universalmente 贸ptima; la elecci贸n depende del contexto y del costo de los errores.\n",
        "\n",
        "El an谩lisis basado en la matriz de confusi贸n es fundamental para la selecci贸n de modelos en aplicaciones reales."
      ],
      "metadata": {
        "id": "CGWHO5JI3q39"
      }
    }
  ]
}